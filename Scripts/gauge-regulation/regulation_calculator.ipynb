{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649a14fd-aead-4a39-992c-a9043dc6433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from exactextract import exact_extract\n",
    "from rasterstats import zonal_stats\n",
    "import geopandas as gpd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea38ec36-2591-4060-bf85-eb7ee0203576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste directory for data files \"basins.shp\", \"gauges.shp\", and \"precipitation.tif\":  spatial-data\n",
      "Select extraction method (1-exactextract or 2-rasterstats):  2\n"
     ]
    }
   ],
   "source": [
    "#print('Enter Directory where the files basins.shp, gauges.shp, and precipitation.tif can be found.\\n')\n",
    "\n",
    "directory = input('Paste directory for data files \"basins.shp\", \"gauges.shp\", and \"precipitation.tif\": ')\n",
    "stats = int(input('Select extraction method (1-exactextract or 2-rasterstats): '))\n",
    "\n",
    "start = time() # Record start time of program execution\n",
    "\n",
    "basins_shape = gpd.read_file(f'{directory}/basins.shp') # Locate and read the 'basin.shp' polygon shapefile\n",
    "gauges_shape = gpd.read_file(f'{directory}/gauges.shp') # Locate and read the 'gauge.shp' point shapefile\n",
    "precipitation = f'{directory}/precipitation.tif' # Location the 'precipitation.tif' source raster\n",
    "\n",
    "basins = basins_shape.drop(columns = 'geometry') # Remove geometry attributes for DI calculation\n",
    "gauges = gauges_shape.drop(columns = 'geometry') # Data acquired from NALRRP and the Government of Canda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add68399-5a0c-4fb7-9e66-12f66b2d0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basin_finder(basins, row, neighbours):\n",
    "    '''Returns a list of subbasin IDs from the dataset (basins) which flow into a particular gauge (row). A dictionary (neighbours) identifies linked subbasins.\n",
    "    The loop pops each subbasin from the stack and appends neighbouring polygons, repeating until the list is empty.'''\n",
    "\n",
    "    stack = [row['SubId']] # Start with just the starting ID in the stack\n",
    "    search = stack.copy()\n",
    "\n",
    "    while stack: # Repeat until stack is empty\n",
    "\n",
    "        inflows = neighbours.get(stack.pop(), []) # Identify shapes flowing into the starting ID\n",
    "\n",
    "        for item in inflows: # Add inflows to the stack and basin tree\n",
    "\n",
    "            search.append(item) # Adds the inflows to both the stack and the subbasin list\n",
    "            stack.append(item)\n",
    "\n",
    "    return search # Return the subbasin list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f18cd5a-55b6-4223-a629-aaadf2528bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basin_map(basins, gauges):\n",
    "    '''Returns a dictionary map linking every subbasin ID with a list of basins that flow into it (basins). Iterates over each stream gauge (gauges). Calls the\n",
    "    basin_finder() function repeatedly and provides feedback on search progress.'''\n",
    "    \n",
    "    basin_map = {} # Initiate dictionary of gauge basins\n",
    "    total_gauges = gauges.shape[0] # Precompute the number of gauges to save processing time\n",
    "    neighbours = basins.groupby('DowSubId')['SubId'].apply(list).to_dict() # Reduce filtering time by creating a dictionary in advance\n",
    "\n",
    "    for key in list(neighbours.keys()): # Iterates over the dictionary\n",
    "        \n",
    "        if int(key) < 0: del neighbours[key] # Removes elements with a negative key, which occurs at the basin mouth\n",
    "    \n",
    "    for index, row in gauges.iterrows(): # Iterate over stream gauges\n",
    "        \n",
    "        basin_map[row['SubId']] = basin_finder(basins, row, neighbours) # Append the search list to the dictionary\n",
    "        print(f'Basin networks processed: {len(basin_map)}/{total_gauges} ({100 * len(basin_map)/total_gauges:.2f}%)', end = '\\r') # Print visual feedback\n",
    "\n",
    "    return basin_map # Return dictionary of subbasin lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93de3c16-bbf5-4404-aa42-fcc6e1e1da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zonal statistics...\n"
     ]
    }
   ],
   "source": [
    "print('Calculating zonal statistics...') # Print visual feedback\n",
    "\n",
    "if stats == 1: # Compute zonal mean for each subbasin using exactextract\n",
    "    \n",
    "    precipitation = exact_extract(precipitation, basins_shape, ['mean'], include_cols = ['SubId'], output = 'pandas')\n",
    "    basins = pd.merge(basins, precipitation, on = 'SubId').rename(columns = {'mean':'Precip_Mean'}) # Join the DataFrames with the 'SubId' field\n",
    "\n",
    "elif stats == 2: # Alternatively, compute zonal mean for each subbasin using rasterstats\n",
    "    \n",
    "    precipitation = zonal_stats(basins_shape, precipitation, stats = 'mean', all_touched = True, geojson_out = True)\n",
    "    basins = pd.DataFrame([f['properties'] for f in precipitation]).rename(columns = {'mean':'Precip_Mean'}) # Construct from the GeoJSON\n",
    "        \n",
    "total_gauges = gauges.shape[0] # Precompute the number of gauges to save processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48afc178-2ac6-4c07-be00-e3c4f1e19020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauges validated: 54/55 (98.18%)\n",
      "Basin networks processed: 55/55 (100.00%)"
     ]
    }
   ],
   "source": [
    "for index, row in gauges.copy().iterrows(): # Check for stream gauges not represented within the network\n",
    "\n",
    "    print(f'Gauges validated: {index}/{total_gauges} ({100 * index/total_gauges:.2f}%)', end = '\\r') # Print visual feedback\n",
    "    if not(row['SubId'] in basins['SubId'].values): # Identify gauges without a corresponding basin\n",
    "\n",
    "        gauges = gauges[gauges['SubId'] != row['SubId']] # Delete the gauge from the dataframe\n",
    "\n",
    "print() # Print a newline\n",
    "gauge_map = basin_map(basins, gauges) # Determine the set of drainage polygons for each stream gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c96318-439b-4978-9e70-f5aad09f226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gauges calculated: 55/55 (100.00%)\n",
      "Execution time: 73.51 seconds\n",
      "Output location: \"spatial-data/gauges_DI.csv\"\n"
     ]
    }
   ],
   "source": [
    "basin_storage = {} # Initiate the storage dictionary\n",
    "print() # Print newline\n",
    "\n",
    "for index, row0 in gauges.iterrows(): # Calculating the DI value\n",
    "\n",
    "    numerator = 0 # Initiate the DI numerator [ac-ft]\n",
    "    precip = 0 # Initiate precipitation value for gauge [mm]\n",
    "    total_area = row0['DrainArea'] # Total drainage area for the gauge site [m2]\n",
    "    check_area = 0 # To be compared with total area\n",
    "    total_gauges = gauges.shape[0] # Precompute the number of gauges to save processing time\n",
    "    \n",
    "    basin_builder = gauge_map[row0['SubId']] # Return all subbasins that flow into the station, removing duplicates.\n",
    "    gauge_basin = basins[basins['SubId'].isin(basin_builder)] # Create a dataframe out of the retrieved values\n",
    "    subbasin_count = gauge_basin.shape[0] # Precompute the number of subbasins to save processing time\n",
    "    \n",
    "    for subindex, subbasin in gauge_basin.iterrows(): # Compute DI for each gauge with the subset of basins retrieved\n",
    "\n",
    "        precip += (subbasin['BasArea'] * subbasin['Precip_Mean']) / total_area # Portion of the mean precipitation weighted average [m2][mm]/[m2] = [mm]\n",
    "        check_area += subbasin['BasArea']\n",
    "        \n",
    "        if subbasin['Lake_Cat'] == 1 and subbasin['Laketype'] in [2, 3]: # Filter for regulated lakes or reservoirs\n",
    "\n",
    "            volume_acft = subbasin['LakeVol'] * 810714 # Convert from km3 to ac-ft [ac-ft]\n",
    "            numerator += volume_acft * (subbasin['DrainArea'] / total_area) # Summation in numerator of DI [ac-ft][m2]/[m2] = [ac-ft]\n",
    "    \n",
    "    area_ac = total_area / 4046.86 # Convert from m2 to ac [ac]\n",
    "    precip /= 304.8 # Convert to ft and convert to average [ft]\n",
    "\n",
    "    gauges.loc[index, 'DI'] = numerator / (precip * area_ac) # Final DI computation [ac-ft]/[ft]/[ac] = 1\n",
    "    \n",
    "    gauges.loc[index, 'CheckArea'] = check_area # For comparison with total area\n",
    "    basin_storage[index] = gauge_basin # Saving subsets for cross-checking\n",
    "\n",
    "    print(f'Gauges calculated: {index + 1}/{total_gauges} ({100 * (index + 1)/total_gauges:.2f}%)', end = '\\r') # Print visual feedback\n",
    "\n",
    "gauges.loc[:, 'AreaError'] = abs(gauges['CheckArea'] - gauges['DrainArea']) / gauges['DrainArea'] # Vector computation of percent error\n",
    "end = time() # Record end time of program execution\n",
    "\n",
    "print(f'\\nExecution time: {end - start:.2f} seconds\\nOutput location: \"{directory}/gauges_DI.csv\"') # Signal completion of the process.\n",
    "gauges.to_csv(f'{directory}/gauges_DI.csv') # Write to .csv file\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gauge_venv3",
   "language": "python",
   "name": "gauge_venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
